[
  {
    "objectID": "tps/tp_4.html#resumen",
    "href": "tps/tp_4.html#resumen",
    "title": "TP4 (1/2): Deep Learning",
    "section": "Resumen",
    "text": "Resumen\nEl TP4 parte 1 (1/2) apunta a familiarizarse con conceptos introductorios de Redes Neuronales y Deep Learning, tales como backpropagation, redes feed forward (densas) y redes convolucionales (CNN). Esta gu√≠a tiene tres ejercicios, de los cuales los primeros dos son entregables.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.\n\n\nLink al repositorio",
    "crumbs": [
      "Practicas",
      "TP4 (1/2): Deep Learning"
    ]
  },
  {
    "objectID": "tps/tp_4.html#red-neuronal-feed-forward-from-scratch",
    "href": "tps/tp_4.html#red-neuronal-feed-forward-from-scratch",
    "title": "TP4 (1/2): Deep Learning",
    "section": "(‚òÖ) 1. Red Neuronal Feed Forward (from Scratch)",
    "text": "(‚òÖ) 1. Red Neuronal Feed Forward (from Scratch)\nEl objetivo de este ejercicio es implementar una red neuronal para la clasificaci√≥n de im√°genes del conjunto de datos CIFAR-10 desde cero utilizando √∫nicamente la librer√≠a NumPy (solamente se usa tensorflow para cargar el dataset por simplicidad). Para ello debes completar el script ej1.py, y presentar los resultados del entrenamiento, tales como visualizaciones de la funci√≥n de Loss y Accuracy en funci√≥n de las √©pocas de entrenamiento, y posteriormente sobre los datos de test. (Puedes presentarlo en un notebook .ipynb)\n\nDescripci√≥n del Problema:\nCIFAR-10 es un conjunto de datos que contiene 60,000 im√°genes (50,000 para train y 10,000 para test) en color (RGB) de 32x32 p√≠xeles, distribuidas en 10 clases diferentes (como aviones, autom√≥viles, aves, etc.). Para este ejercicio, implementar√°s una red neuronal con la siguiente arquitectura:\nUna capa de entrada que recibe las im√°genes aplanadas (tama√±o 32x32x3). Una capa oculta con 100 neuronas y funci√≥n de activaci√≥n ReLU. Una capa de salida con 10 neuronas y funci√≥n de activaci√≥n softmax, una por cada clase.",
    "crumbs": [
      "Practicas",
      "TP4 (1/2): Deep Learning"
    ]
  },
  {
    "objectID": "tps/tp_4.html#implementaci√≥n-de-una-red-neuronal-convolucional-cnn-para-clasificaci√≥n-de-im√°genes.",
    "href": "tps/tp_4.html#implementaci√≥n-de-una-red-neuronal-convolucional-cnn-para-clasificaci√≥n-de-im√°genes.",
    "title": "TP4 (1/2): Deep Learning",
    "section": "(‚òÖ) 2. Implementaci√≥n de una red neuronal convolucional (CNN) para clasificaci√≥n de im√°genes.",
    "text": "(‚òÖ) 2. Implementaci√≥n de una red neuronal convolucional (CNN) para clasificaci√≥n de im√°genes.\nResuelve el problema de clasificaci√≥n de CIFAR-10, pero usando redes neuronales convolucionales Presenta tus resultados en el notebook ej2.ipynb. Te recomendamos fuertemente usar Google Colab, ya que a diferencia de tu implementaci√≥n en el ejercicio anterior, las librer√≠as Keras y Pytorch est√°n optimizadas para tareas paralelizables.",
    "crumbs": [
      "Practicas",
      "TP4 (1/2): Deep Learning"
    ]
  },
  {
    "objectID": "tps/tp_4.html#micro-keras-from-scratch",
    "href": "tps/tp_4.html#micro-keras-from-scratch",
    "title": "TP4 (1/2): Deep Learning",
    "section": "(‚òÖ‚òÖ‚òÖ) 3. Micro Keras from scratch",
    "text": "(‚òÖ‚òÖ‚òÖ) 3. Micro Keras from scratch\nEl objetivo de este ejercicio es desarrollar una biblioteca modular en Python para la construcci√≥n de redes neuronales feedforward de manera flexible desde cero, utilizando solo la librer√≠a NumPy.\n\nEstructura (recomendada) del C√≥digo\nLa biblioteca deber√° estar organizada organizada en los siguientes m√≥dulos:\n\nmetrics.py\nlosses.py\nactivations.py\nmodels.py\nlayers.py\noptimizers.py\n\n\n\nDescripci√≥n de los M√≥dulos\n\n1. metrics.py\nAccuracy: Calcula la precisi√≥n de las predicciones. MSE: Calcula el error cuadr√°tico medio (Mean Squared Error).\n\n\n2. losses.py\nLoss: Interfaz de las funciones de costo que define el m√©todo call y gradient. MSE: Implementaci√≥n de la funci√≥n de costo Mean Squared Error.\n\n\n3. activations.py\nReLU: Implementa la funci√≥n de activaci√≥n ReLU y su derivada. Tanh: Implementa la funci√≥n de activaci√≥n Tanh y su derivada. Sigmoid: Implementa la funci√≥n de activaci√≥n Sigmoid y su derivada.\n\n\n4. models.py\nNetwork: Clase que implementa una red neuronal feedforward. Deber√° permitir agregar capas, compilar el modelo, realizar forward propagation, backward propagation, entrenar el modelo y hacer predicciones.\n\n\n5. layers.py\nBaseLayer: Clase base para cualquier tipo de capa. Define las interfaces forward y backward. Input: Representa la capa de entrada de la red neuronal, heredando de BaseLayer. Layer: Clase base para capas con pesos. Hereda de BaseLayer. Dense: Representa una capa densa (fully connected) que hereda de Layer.\n\n\n6. optimizers.py\nOptimizer: Interfaz para optimizadores. Define el m√©todo update. SGD: Implementa el optimizador Stochastic Gradient Descent.\n\n\n\nCaso de prueba\nPara validar la implementaci√≥n, se utilizar√° el problema XOR (un problema facilito para que puedan hacer pruebas r√°pidas).",
    "crumbs": [
      "Practicas",
      "TP4 (1/2): Deep Learning"
    ]
  },
  {
    "objectID": "tps/tp_2.html",
    "href": "tps/tp_2.html",
    "title": "TP2: Linear and Tree models",
    "section": "",
    "text": "El TP2 apunta a familiarizarse con los estimadores lineales (lineal y log√≠stico) y los modelos de √°rboles, ademas de obligarlos a trabajar en la estructura de c√≥digo de una librer√≠a muy sencilla, y tambi√©n de trabajar en un pipeline end to end. Esta gu√≠a tiene dos ejercicios solamente, pero ambos son entregables.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.",
    "crumbs": [
      "Practicas",
      "TP2: Linear and Tree models"
    ]
  },
  {
    "objectID": "tps/tp_2.html#resumen",
    "href": "tps/tp_2.html#resumen",
    "title": "TP2: Linear and Tree models",
    "section": "",
    "text": "El TP2 apunta a familiarizarse con los estimadores lineales (lineal y log√≠stico) y los modelos de √°rboles, ademas de obligarlos a trabajar en la estructura de c√≥digo de una librer√≠a muy sencilla, y tambi√©n de trabajar en un pipeline end to end. Esta gu√≠a tiene dos ejercicios solamente, pero ambos son entregables.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.",
    "crumbs": [
      "Practicas",
      "TP2: Linear and Tree models"
    ]
  },
  {
    "objectID": "tps/tp_2.html#your-own-scikit-learn-library",
    "href": "tps/tp_2.html#your-own-scikit-learn-library",
    "title": "TP2: Linear and Tree models",
    "section": "(‚òÖ) 1. Your own Scikit Learn library",
    "text": "(‚òÖ) 1. Your own Scikit Learn library\nEncontrar√° en la carpeta ‚Äúej1‚Äù archivos relacionados a Regresi√≥n Lineal, Regresi√≥n Log√≠stica y Tree Stumps. Todos heredan de una interfaz com√∫n, Estimator, y donde adem√°s los modelos lineales se entrenan por SGD. Por √∫ltimo, se provee GradientBoostingEstimator, que permite generar un ensamble de modelos a partir de Gradient Boosting.\nDicho esto, resuelva los siguientes incisos:\n\nImplemente el proceso de entrenamiento de SGD en SGDEstimator.\nImplemente LinearRegressor.\nImplemente LogisticClassifier.\nEn la notebook explore.ipynb, explore dataset_A.pkl y dataset_B.pkl, y elija el modelo correcto para cada dataset. ¬øQu√© miro para tomar esa decisi√≥n?\nEn la notebook train.ipynb use esas clases para entrenal los modelos respectivos. Utilice un split de train/test y mida la precisi√≥n para cada caso.\nEn la notebook explore.ipynb, explore dataset_C.pkl e identifique qu√© comportamineto se observa frente a las variables de entrada.\nImplemente la clase TreeStumpRegressor.\nImplemente la clase GradientBoostingEstimator.\nIntente utilizar una regresi√≥n lineal y un clasificador log√≠stico para fittear dataset_C.pkl. Luego utilice GradientBoosting con modelos de √°rboles. ¬øC√≥mo se compara la precisi√≥n de √°mbos modelos? ¬øC√≥mo explica este fen√≥meno?\nReescriba todo el procedimiento en la notebook sklearn.ipynb utilizando la librer√≠a de sklearn en vez de su implementaci√≥n. ¬øQu√© diferencias nota? ¬øA qu√© se deben estas diferencias?\n\nEste ejercicio es entregable!\nAdem√°s: los datasets provistos est√°n en formato pickle, un tipo de serializaci√≥n com√∫n de python. Puede leerlos a trav√©s de una apertura binaria de los archivos, utilizando pickle.load.",
    "crumbs": [
      "Practicas",
      "TP2: Linear and Tree models"
    ]
  },
  {
    "objectID": "tps/tp_2.html#your-first-end-to-end-machine-learning-pipeline",
    "href": "tps/tp_2.html#your-first-end-to-end-machine-learning-pipeline",
    "title": "TP2: Linear and Tree models",
    "section": "(‚òÖ) 2. Your first end to end Machine Learning pipeline",
    "text": "(‚òÖ) 2. Your first end to end Machine Learning pipeline\nA partir del ejercico 5 de la pr√°ctica anterior (EDA), vamos a implementar el primer pipeline end to end de machine learning. El mismo consiste en:\n\nCargar los datos del dataset provisto anteriormente, splittear en train y test,\nPreprocesar los datos en un formato adecuado para entrenar un modelo,\nDefinir una grilla de b√∫squeda de hiperpar√°metros (los que corresponda seg√∫n la arquitectura)\nUtilizar modelos lineales y de √°rboles (random forest, gradient boosting) para encontrar un predictor adecuado. Se recomienda LightGBM. Buscar a trav√©s de KFold o alguna t√©cnica de validaci√≥n cruzada.\nGraficar y reportar m√©tricas de performance y gr√°ficas de calibraci√≥n para los datos de test.\nEscribir un pipeline de Scikit Learn que resuma los pasos anteriores.\n\nEncontrar√° un archivo ej2.ipynb donde implementar este ejercicio.",
    "crumbs": [
      "Practicas",
      "TP2: Linear and Tree models"
    ]
  },
  {
    "objectID": "tps/tp_0.html",
    "href": "tps/tp_0.html",
    "title": "TP0: Tooling",
    "section": "",
    "text": "El TP0 apunta a familiarizarse con herramientas que utilizaremos durante el curso y, si bien no son precisamente de aprendizaje profundo, si son pr√°cticas usuales del campo del desarrollo de software y permiten aspectos como el versionado, la comunicaci√≥n, en encapsulamiento, entre otros.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.\n\nCompletar este TP en su totalidad es una tarea sumamente extensa, por lo que se recomienda al lector tratar al mismo como un ‚Äúrepositorio de ideas‚Äù‚Äîa excepci√≥n de los ejercicios obligatorios‚Äîes decir, un lugar a d√≥nde haya una referencia de un seleccionado de cosas que le pueden ser de utilidad para construir sistemas de informaci√≥n.\nNota: Parte de esta pr√°ctica fue escrita con auxilio de alg√∫n LLM - so you may find some weird wording here and there.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#resumen",
    "href": "tps/tp_0.html#resumen",
    "title": "TP0: Tooling",
    "section": "",
    "text": "El TP0 apunta a familiarizarse con herramientas que utilizaremos durante el curso y, si bien no son precisamente de aprendizaje profundo, si son pr√°cticas usuales del campo del desarrollo de software y permiten aspectos como el versionado, la comunicaci√≥n, en encapsulamiento, entre otros.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.\n\nCompletar este TP en su totalidad es una tarea sumamente extensa, por lo que se recomienda al lector tratar al mismo como un ‚Äúrepositorio de ideas‚Äù‚Äîa excepci√≥n de los ejercicios obligatorios‚Äîes decir, un lugar a d√≥nde haya una referencia de un seleccionado de cosas que le pueden ser de utilidad para construir sistemas de informaci√≥n.\nNota: Parte de esta pr√°ctica fue escrita con auxilio de alg√∫n LLM - so you may find some weird wording here and there.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#ide",
    "href": "tps/tp_0.html#ide",
    "title": "TP0: Tooling",
    "section": "IDE ‚òÖ",
    "text": "IDE ‚òÖ\n\nVisual Studio Code (VSCode)\nUn Entorno de Desarrollo Integrado (IDE) es una herramienta esencial para cualquier programador. Facilita la tarea de escribir y depurar c√≥digo, ofreciendo funcionalidades como resaltado de sintaxis, autocompletado, gesti√≥n de versiones, entre otras. En este curso, recomendamos en Visual Studio Code (VSCode), uno de los IDEs m√°s populares y vers√°tiles.\nInstrucciones:\n\nDescarga e Instalaci√≥n:\n\nVisita la p√°gina oficial de Visual Studio Code: https://code.visualstudio.com/\nSelecciona la versi√≥n adecuada para tu sistema operativo (Windows, MacOS, Linux) y desc√°rgala.\nSigue las instrucciones de instalaci√≥n proporcionadas en la p√°gina o por el instalador.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#git",
    "href": "tps/tp_0.html#git",
    "title": "TP0: Tooling",
    "section": "Git ‚òÖ",
    "text": "Git ‚òÖ\nGit es una herramienta de control de versiones esencial para cualquier desarrollador. ¬øPor qu√©? Porque te permite tener un registro detallado y organizado de todos los cambios que hac√©s en tu c√≥digo. Imaginate que es como un gran libro de historia, donde cada cambio que hac√©s en tu proyecto queda anotado, y pod√©s volver atr√°s en el tiempo si algo no anda bien.\nPero Git no es solo un guardi√°n del pasado; tambi√©n es fundamental para trabajar en equipo. Permite que varias personas colaboren en el mismo proyecto sin pisarse los talones. Cada uno puede trabajar en su rama, hacer cambios, y despu√©s juntar todo sin tantos dramas.\nDurante el curso, vamos a meterle mano a Git de a poco. Vamos a empezar con lo b√°sico: crear repositorios, hacer commits, manejar branches, y entender c√≥mo funciona el asunto de los merge. Despu√©s, vamos a explorar caracter√≠sticas m√°s avanzadas y aprender a resolver conflictos, que siempre aparecen cuando menos los esper√°s.\nAdem√°s, vamos a usar GitHub, que es como el barrio de Git en internet. Ah√≠ vamos a compartir nuestros c√≥digos, colaborar en proyectos y, sobre todo, aprender a mover el ambo en este mundo del desarrollo colaborativo.\nPor √∫ltimo, a lo largo del curso vamos a usar una herramienta que se llama GitHub Classroom. Ah√≠ mismo vamos a poder hacer correcciones (con la metodolog√≠a usual de correcciones de Git - Pull Requests) y, adem√°s de eso, se van a correr autom√°gicamente suites de tests que les van a servir de feedback instant√°neo para saber si el c√≥digo que est√°n haciendo est√° correcto (da lo que deber√≠a dar) o no.\n\nEjercicios\n\n(‚òÖ) GitHub Account:\n\nCrear un Repositorio en GitHub:\n\n(Crea y) Inicia sesi√≥n en tu cuenta de GitHub.\nSi no lo ten√©s, instala git en tu computadora.\nCrea un nuevo repositorio en tu cuenta de GitHub. Dale un nombre como tp0-test .\nMarca la opci√≥n de inicializar el repositorio con un archivo README.\n\nClonar el Repositorio:\n\nUtiliza el comando git clone seguido de la URL de tu repositorio para clonarlo en tu equipo local.\n\nCrear y Usar una Branch:\n\nCrea una nueva branch en tu repositorio local, por ejemplo, feature-branch.\nCambia a esta branch con git checkout feature-branch. Se pueden hacer ambos pasos al mismo tiempo con git checkout -b feature-branch\nEscribe un archivo README.md con tu nombre, tu carrera y un fun fact tuyo. Guarda este archivo en tu repositorio local.\n\nPushear Cambios y Crear un Pull Request (PR):\n\nPushea tus cambios a GitHub con git push.\nVe a tu repositorio en GitHub y crea un PR desde tu nueva branch hacia la branch principal (main o master).\n\nMergear el Pull Request:\n\nCompleta el proceso de revisi√≥n de c√≥digo (si es aplicable) y mergea el PR.\n\n\n(‚òÖ) GitHub Classroom\n\nAcceso a GitHub Classroom:\n\nUtiliza el enlace proporcionado por la c√°tedra para acceder al GitHub Classroom de tu curso (https://classroom.github.com/a/KpD5PDYo). Esto va a generar un nuevo repositorio para tu cuenta.\nEn el nuevo repositorio creado en tu cuenta encontrar√°s en su interior algunas carpetas asociadas a este trabajo pr√°ctico.\n\nCompletar el Assignment:\n\nCre√° un archivo que se llame ‚Äúfun_fact.txt‚Äù, con alg√∫n fun fact tuyo en su interior.\nPushe√° los cambios al repositorio.\nEsto va a crear autom√°gicamente un PR que se llama ‚ÄúFeedback‚Äù, a donde vamos a poder interactuar para chequear que el c√≥digo escrito est√© correcto.\n\nUso del Autograding:\n\nRevis√° el Autograding (ver aqu√≠ como) para ver que el test (Ejercicio 2) pase correctamente.\n\n\n(‚òÖ‚òÖ) GitFlow\n\nCrear y Usar Branches de Desarrollo y Features:\n\nCrea una branch mainy haz algunos cambios en ella.\nLuego, crea dos branches de caracter√≠sticas, F1 y F2, bas√°ndote en main. Hac√© cambios en archivos similares en ambas branches - por ejemplo, en el fun_fact.txt que mencionamos anteriormente. Intent√° cambiar un fun fact por un unfun-fact en una branch, y por otro weird_fact en la otra.\n\nMergear Branches y Resolver Conflictos:\n\nMergear F1 con main.\nIntent√° mergear F2 con mainy maneja los conflictos que surjan.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#python",
    "href": "tps/tp_0.html#python",
    "title": "TP0: Tooling",
    "section": "Python ‚òÖ",
    "text": "Python ‚òÖ\nPython es un lenguaje de programaci√≥n de alto nivel. Se ha convertido en uno de los lenguajes m√°s populares en el campo de la inteligencia artificial y el aprendizaje autom√°tico (AI/ML) debido a su simplicidad y a la amplia gama de bibliotecas disponibles.\nEn este curso, vamos a explorar las caracter√≠sticas b√°sicas de Python, incluyendo su sintaxis, estructuras de datos, funciones y clases. Adem√°s, nos sumergiremos en bibliotecas espec√≠ficas como Numpy, Pandas y Matplotlib, las cuales son fundamentales en el an√°lisis de datos y visualizaci√≥n. M√°s adelante, tambi√©n utilizaremos librer√≠as especializadas de aprendizaje autom√°tico, como Torch, HuggingFace, o Xgboost.\n\nDescarga e instala Python desde python.org.\nVerifica la instalaci√≥n ejecutando python --version en tu terminal.\n\nConda es un gestor de paquetes que nos permite tener distintos ambientes en nuestra computadora, con distintos ejecutables de python instalados y adem√°s con varias versiones de librer√≠as por ambiente. Para instalar conda:\n\nInstala miniconda siguiendo las instrucciones en el sitio de Conda.\nCre√° un ambiente en conda llamado ‚Äútp0‚Äù con el siguiente comando: conda create -n tp0 python=3.9.\nActivalo con conda activate tp0.\nInstal√° las siguientes librer√≠as: conda install pytest numpy pandas matplotlib.\n\nPor √∫ltimo, los siguientes son ejercicios para recorrer el lenguaje de forma amena. Para que los tests autom√°ticos funcionen, cada uno de los ejercicios debe vivir en la carpeta python/src/ejericico_N.py , donde N es el n√∫mero de ejercicio correspondiente.\n\nEjercicios\n\n(‚òÖ) Hola Mundo:\n\nHola mundo: Escribe un script en Python que guarde el string ‚ÄúHola mundo!‚Äù en una variable llamada hola_mundo y que luego la imprima usando print .\n\n(‚òÖ) Funciones:\n\nSuma de N√∫meros: Crea una funci√≥n en Python llamada sumar(a, b) que reciba dos n√∫meros como argumentos y devuelva su suma.\nPit√°goras: Crea una funci√≥n en Python llamada pitagoras(a, b, tipo=\"hipotenusa\") que reciba dos n√∫meros como argumentos (a) la hipotenusa si el tipo es ‚Äúhipotenusa‚Äù o (b) el cateto si el tipo es ‚Äúcateto‚Äù. Pensar c√≥mo se puede hacer para tomar el lado m√°s grande (a o b) para el segundo caso.\n\n(‚òÖ) Clases:\n\nRect√°ngulo: Define una clase Rectangulo en Python que se inicialice con longitud y ancho. La clase debe tener dos m√©todos, area y perimetro, que devuelvan respectivamente el √°rea y el per√≠metro del rect√°ngulo.\nCuadrado: Define una clase Cuadrado que herede de rect√°ngulo y que s√≥lo se inicialice con lado.\n\n(‚òÖ) NumPy:\n\nEstad√≠sticas de un arreglo: Crea una funci√≥n stats(a) que tome un array de floats python, y que calcule y devuelve la media y la desviaci√≥n est√°ndar de esos n√∫meros usando Numpy para crear un array de n√∫meros.\nProducto matricial: Crea una funci√≥n matmul(a, b) que tome dos matrices a y b y devuelva el producto entre ellas, si son compatibles, y que retorne un ValueError si no.\nAutovectores y autovalores: Cree una funci√≥n eigen(a) que devuelva los autovectores y autovalores de una matriz si es cuadrada, y retorne ValueError sino.\n\n(‚òÖ) Pandas:\n\nLectura de CSV: Cree una funci√≥n read_data que lea el archivo data/python/ej5.csv que se encuentra en el repositorio dentro de un DataFrame y retorne una lista con las columnas, y un entero con la cantidad de filas que el archivo posee.\nModificaci√≥n de datos: Cree funci√≥n que modify_data tome los datos anteriormente mencionados, cree una nueva columna, mes, a partir de fecha (recomendado: usar datetime) y devuelva el DataFrame modificado. Pista: puede usar apply.\nAgrupaci√≥n: Cree funci√≥n group_data que tome los datos anteriormente mencionados, cree una nueva y retorne el valor total de las ventas y de los costos (sumando la columna valor, agrupando por tipo).",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#sistema-operativo",
    "href": "tps/tp_0.html#sistema-operativo",
    "title": "TP0: Tooling",
    "section": "Sistema Operativo (‚òÖ‚òÖ)",
    "text": "Sistema Operativo (‚òÖ‚òÖ)\nEn el amplio mundo del desarrollo de software y, espec√≠ficamente en √°reas como el aprendizaje autom√°tico y la ciencia de datos, es fundamental tener una base s√≥lida en el manejo de sistemas operativos. Para nuestro curso, ser√≠a ideal para no sufrir innecesariamente tener alg√∫n sistema operativo que brinde acceso a una terminal tipo GNU, como lo son las distintas distribuciones de Linux. Esto se debe a que Linux ofrece una gran versatilidad, una comunidad de soporte activa, y es ampliamente adoptado en entornos de investigaci√≥n y producci√≥n.\nAhora, si est√°s utilizando Windows, no te preocupes. Hay una soluci√≥n pr√°ctica llamada Subsistema de Windows para Linux (WSL), que te permite ejecutar un entorno de Linux directamente en Windows. Esto es ideal para quienes prefieren o necesitan mantener Windows como su sistema operativo principal, pero igual quieren disfrutar de las ventajas de Linux.\nInstalar WSL te permitir√° trabajar en un ambiente similar al que encontrar√≠as en un sistema operativo basado en Unix, lo cual es una habilidad valiosa en el campo de la inform√°tica. A lo largo del curso, veremos c√≥mo aprovechar estas herramientas para maximizar tu aprendizaje y eficiencia en la programaci√≥n y gesti√≥n de proyectos de software.\n\nInstrucciones para Instalar WSL en Windows\n\nHabilita el Subsistema de Windows para Linux:\n\nAbre PowerShell como administrador y ejecuta:\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n\nHabilita la Plataforma de M√°quina Virtual:\n\nEn el mismo PowerShell ejecuta:\ndism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\nReinicia tu computadora para completar la instalaci√≥n.\n\nDescarga el Paquete de Actualizaci√≥n del Kernel de Linux para WSL 2:\n\nDescarga el paquete de actualizaci√≥n desde el sitio oficial de Microsoft. Busca ‚ÄúWSL2 Linux kernel update package for x64 machines‚Äù en la p√°gina de Microsoft.\n\nEstablece WSL 2 como Versi√≥n Predeterminada:\n\nAbre nuevamente PowerShell y ejecuta:\nwsl --set-default-version 2\n\nInstala tu Distribuci√≥n de Linux Favorita:\n\nAbre Microsoft Store y busca la distribuci√≥n de Linux que prefieras (Ubuntu, Debian, etc.).\nSelecciona la distribuci√≥n y haz clic en ‚ÄúObtener‚Äù para instalarla.\n\nConfigura tu Distribuci√≥n de Linux:\n\nUna vez instalada la distribuci√≥n, √°brela desde el men√∫ de inicio.\nLa primera vez que la abras, tendr√°s que configurar tu cuenta de usuario y contrase√±a.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#jupyter",
    "href": "tps/tp_0.html#jupyter",
    "title": "TP0: Tooling",
    "section": "Jupyter (‚òÖ‚òÖ)",
    "text": "Jupyter (‚òÖ‚òÖ)\nEn el √°mbito de la ciencia de datos y el aprendizaje autom√°tico, Jupyter Notebook se ha establecido como una herramienta esencial. Permite combinar c√≥digo, texto enriquecido, visualizaciones y otros elementos multimedia en un solo documento interactivo.\nPara quienes usan Python y otras herramientas de an√°lisis de datos, Jupyter ofrece una forma pr√°ctica de experimentar con el c√≥digo y visualizar los resultados al instante. En este curso, aprenderemos a utilizar Jupyter Notebook de manera local y tambi√©n exploraremos Google Colab, una versi√≥n basada en la nube que se integra perfectamente con Google Drive, proporcionando un entorno poderoso y colaborativo para el desarrollo de proyectos de ciencia de datos.\n\nEjercicios\n1. (‚òÖ‚òÖ) Uso de Jupyter Notebook Local\n\nInstalaci√≥n y Ejecuci√≥n:\n\nInstala Jupyter Notebook en tu m√°quina local. Puedes hacerlo instalando Anaconda, que incluye Jupyter, o instal√°ndolo mediante pip con pip install notebook.\nInicia Jupyter Notebook ejecutando jupyter notebook en tu terminal. Esto abrir√° una nueva ventana o pesta√±a en tu navegador predeterminado.\n\nCrea una nueva notebook, escribe un c√≥digo simple en Python (por ejemplo, imprimir ‚ÄúHola, mundo!‚Äù) y ejecuta la celda.\nEn una celda siguiente creemos una funci√≥n con numpy, para dibujar algunas funciones con matplotlib como ejemplo:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Genera un rango de valores\nx = np.linspace(-10, 10, 400)\n\n# Calcula valores para diferentes funciones\ny_sin = np.sin(x)\ny_cos = np.cos(x)\ny_tan = np.tan(x)\n\n# Configura el gr√°fico\nplt.figure(figsize=(12, 6))\n\n# Dibuja cada funci√≥n\nplt.plot(x, y_sin, label='seno')\nplt.plot(x, y_cos, label='coseno')\nplt.plot(x, y_tan, label='tangente')\n\n# A√±ade una leyenda\nplt.legend()\n\n# Muestra el gr√°fico\nplt.show()\n\nAlgunas opciones de IPython nos permiten interactuar con la terminal directamente desde una celda de Jupyter, y tambi√©n permiten configurar el comportamiento de la notebook en s√≠ (autoreload de imports, matplotlib interactivo, etc). Juegue con la siguiente celda, que ejemplifica el concepto:\n\n# Muestra la lista de archivos en el directorio actual\n%ls\n\n# Autoreload de m√≥dulos importados (√∫til para desarrollo)\n%load_ext autoreload\n%autoreload 2\n\n# Permite que los gr√°ficos de matplotlib se muestren interactivamente\n%matplotlib inline\n\n# Ejemplo de ejecuci√≥n de comandos de shell\n!echo \"Hola desde el shell\"\n2. (‚òÖ‚òÖ) Uso de Google Colab con Informaci√≥n de Google Drive\n\nConfiguraci√≥n y Uso:\n\nAccede a Google Colab.\nInicia sesi√≥n con tu cuenta de Google si a√∫n no lo has hecho.\nCrea una nueva notebook.\nEn una celda, escribe y ejecuta el siguiente c√≥digo para montar tu Google Drive:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nNavega a trav√©s de tus archivos de Google Drive desde la barra lateral de Colab.\n\nCarga un archivo de datos desde tu Google Drive en la notebook de Google Colab, realiza una operaci√≥n simple (como leer el archivo si es un CSV) y muestra los resultados.\n\n3. (‚òÖ‚òÖ‚òÖ) Creaci√≥n y Publicaci√≥n de un Documento con Quarto\nQuarto es una herramienta poderosa que extiende las capacidades de Jupyter Notebooks, permitiendo una mayor flexibilidad en la creaci√≥n de documentos y presentaciones atractivas. Es ideal para preparar informes profesionales y cient√≠ficos, as√≠ como presentaciones interactivas.\n\nInstalaci√≥n y Configuraci√≥n:\n\nPara instalar Quarto, visita su p√°gina web oficial y sigue las instrucciones de instalaci√≥n.\nUna vez instalado, crea un nuevo proyecto de Quarto en un directorio de tu elecci√≥n.\nDentro de tu proyecto Quarto, crea un documento que combine texto enriquecido, c√≥digo en Python y sus respectivas salidas.\nA√±ade elementos avanzados como gr√°ficos interactivos o widgets.\nUtiliza las herramientas de formato de Quarto para darle un dise√±o profesional a tu documento.\nGenera una salida en el formato de tu elecci√≥n (HTML, PDF, etc.) y renderizalo. Eso te va a dar algo en HTML que podr√≠as subir a una p√°gina, o un PDF para presentar.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#bases-de-datos",
    "href": "tps/tp_0.html#bases-de-datos",
    "title": "TP0: Tooling",
    "section": "Bases de Datos (‚òÖ‚òÖ)",
    "text": "Bases de Datos (‚òÖ‚òÖ)\nLas bases de datos son un componente crucial en el mundo del machine learning y el an√°lisis de datos. Nos permiten almacenar, organizar y acceder a grandes vol√∫menes de informaci√≥n de manera eficiente, lo que es esencial para entrenar modelos de machine learning con datos precisos y variados. Existen dos tipos principales de bases de datos: relacionales y no relacionales. Las bases de datos relacionales, como MySQL o PostgreSQL, utilizan una estructura de tablas y son excelentes para datos estructurados y consultas complejas. Por otro lado, las bases de datos no relacionales, como MongoDB o Cassandra, ofrecen mayor flexibilidad para almacenar datos no estructurados.\nNos vamos a concentrar en usar solo una base de datos muy sencilla para ilustrar esto: SQLite. Esto es algo que no necesita setupear ni instalar nada, y desde python es, de hecho, muy sencillo de usar. En el futuro utilizaremos PostgreSQL para alguno de los proyectos que puedan llegar a surgir.\nNota: Si quieren practicar SQL, les recomiendo resolver el robo del patito de hule de Harvard: https://cs50.harvard.edu/summer/2022/psets/7/fiftyville/.\n\nEjercicios\n1. (‚òÖ‚òÖ) Nuestra primera base de datos con SQLite\nVamos a armar el siguiente modelito de datos, super sencillo, en una base de datos: vamos a introducir algunos datos y luego responder algunas preguntas.\n\n\n\nUntitled\n\n\nA partir del siguiente snippet de c√≥digo, cree una base de datos en el archivo db_file.db :\nimport sqlite3\n\n# Conectar a la base de datos SQLite:\n\nconexion = sqlite3.connect('db_file.db')\ncursor = conexion.cursor()\n\n# Crear las tablas (TODO)\ncursor.execute('''\nCREATE TABLE alumnos (FILL_ME)\nCREATE TABLE materias (FILL_ME)\nCREATE TABLE notas (FILL_ME)\n''')\n\n# Insertar datos (TODO)\n\nalumnos = [(1, \"Agustin\", \"Bernardo\", 1234567, \"28/04/1995\"), ...]\nmaterias = [(1, \"MLF\", [\"fisica\", \"teleco\", \"doctorado\"]), ...]\n\n# Insertar datos\ncursor.executemany('INSERT INTO alumnos VALUES (?,?,?,?,?)', alumnos)\ncursor.executemany('INSERT INTO materias VALUES (?,?,?)', materias)\n\n# Guardar (commit) los cambios\nconexion.commit()\n\nEscriba una query que dado un nombre de un alumno y una materia, guarde su nota.\nEscriba queries que permitan calcular:\n\nPromedio hist√≥rico de un alumno.\nPromedio de la carrera.\nPromedio por carrera para cada materia.\nCertificado anal√≠tico de un alumno.\n\nCorra esta queries en python y muestre los resultados.\n\nNota: Para correr los tests autom√°ticos en autograding, respete el formato de las tablas y suba el archivo ‚Äú.db‚Äù en conjunto con el c√≥digo. Esto es un antipattern, es solo por motivos did√°cticos. Jam√°s committee una base de datos a un repositorio.\n2. (‚òÖ‚òÖ‚òÖ) ORMs y SQLAlchemy\nResuelva el ejercicio (1) utilizando SQLAlchemy en vez de el conector por defecto de SQLite. ¬øPor qu√© es com√∫n utilizar ORMs en sistemas de software productivos? Nota: ‚ÄúPorque es m√°s fachero‚Äù casi que puede ser una respuesta adecuada.\n3. (‚òÖ‚òÖ‚òÖ) Migraciones (Alembic)\nResuelva el ejercicio (1) utilizando Alembic para manejar el versionado de la base de datos en vez de crearla a trav√©s del script propuesto. ¬øPor qu√© es importante mantener un versionado de bases de datos? ¬øQu√© rol cubren las migraciones?",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#apis",
    "href": "tps/tp_0.html#apis",
    "title": "TP0: Tooling",
    "section": "APIs (‚òÖ‚òÖ)",
    "text": "APIs (‚òÖ‚òÖ)\nAPI es un acr√≥nimo para ‚ÄúApplication Programming Interface‚Äù. Para poder conectar una aplicaci√≥n con otra, es com√∫n utilizar este concepto. Por ejemplo, si queremos que nuestra aplicaci√≥n sea capaz de utilizar alguna aplicaci√≥n que se provee en internet, o si queremos que nuestra aplicaci√≥n pueda ser usada a trav√©s de internet.\nExisten centenas de protocolos distintos para poder utilizar estas interfaces. No obstante, nos vamos a concentrar en uno: REST APIs (por ‚ÄúRepresentation State Transfer‚Äù). Vamos a usar, desde Python, FastAPI (https://fastapi.tiangolo.com/) para poder hacer APIs.\nUn concepto importante dentro de esto es el de asynchronous I/O, que queda fuera del scope de este curso (o al menos de este TP), pero se invita al lector a darle un vistazo: https://docs.python.org/3/library/asyncio-task.html.\n\nEjercicios\n1. (‚òÖ‚òÖ) Nuestro primer servidor con FastAPI\nSiguiendo el ejemplo que se encuentra en la documentaci√≥n de FastAPI (https://fastapi.tiangolo.com/tutorial/first-steps/), inicializar un servidor que devuelva n√∫meros aleatorios en la ruta ‚Äú/‚Äù al hacer get, y que permita obtener un valor al azar al pasar una lista de nombres en la direcci√≥n ‚Äú/‚Äù al hacer put.\n2. (‚òÖ‚òÖ‚òÖ) SQL desde FastAPI\nSiguiendo el ejemplo que se encuentra en la documentaci√≥n de FastAPI (https://fastapi.tiangolo.com/tutorial/sql-databases/), inicializador un servidor con una base de datos local que permita resolver el ejercicio 1 de SQL a trav√©s de una API, e implementar la API que permita obtener los promedios anteriormente mencionados a trav√©s de los endpoints correctos.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#code-quality",
    "href": "tps/tp_0.html#code-quality",
    "title": "TP0: Tooling",
    "section": "Code Quality (‚òÖ‚òÖ‚òÖ)",
    "text": "Code Quality (‚òÖ‚òÖ‚òÖ)\nEl testing unitario es una pr√°ctica esencial en el desarrollo de software. Nos permite validar la funcionalidad de cada componente de manera aislada, asegurando que cada parte del c√≥digo funcione seg√∫n lo esperado. Esta metodolog√≠a es clave para identificar y corregir errores tempranamente, facilitando un desarrollo m√°s √°gil y eficiente.\nEl code coverage mide el porcentaje de c√≥digo que est√° siendo cubierto por tests autom√°ticos. Esta m√©trica es importante para asegurarnos de que nuestras pruebas abarcan una amplia extensi√≥n del c√≥digo, lo que reduce la posibilidad de que existan errores no detectados.\nUna buena pr√°ctica en el desarrollo de software es mantener un formato de c√≥digo consistente y legible. El formateo de c√≥digo ayuda a estandarizar el estilo a lo largo del proyecto, haciendo el c√≥digo m√°s accesible y f√°cil de entender para todos los miembros del equipo.\nEl uso de tipado (typing) en Python contribuye a la claridad y robustez del c√≥digo. Aunque Python es un lenguaje de tipado din√°mico, el tipado est√°tico puede ayudar a prevenir ciertos errores y mejorar la mantenibilidad del c√≥digo.\nEl an√°lisis est√°tico del c√≥digo es el proceso de revisar y analizar el c√≥digo fuente sin ejecutarlo. Esta t√©cnica puede detectar errores, bugs, y problemas de estilo, as√≠ como mejorar la calidad y seguridad del c√≥digo.\n\nHerramientas en Python\nPara aplicar estas pr√°cticas en Python, contamos con varias herramientas √∫tiles:\n\nPytest: Facilita la escritura y ejecuci√≥n de pruebas unitarias.\nBlack: Una herramienta de formateo de c√≥digo que asegura la consistencia del estilo.\nCoverage: Mide el code coverage para garantizar la efectividad de las pruebas.\nFlake8: Proporciona an√°lisis de estilo y errores potenciales en el c√≥digo.\nMypy: Realiza un chequeo de tipos est√°ticos para detectar problemas de tipado.\n\n\n\nEjercicios\nPartiendo del siguiente script (que est√° claramente err√≥neo):\ndef multiplicar(b, a):\nreturn a * b\n\ndef sumar(a,b):\nreturn a+b\n\n(‚òÖ‚òÖ‚òÖ) Testing con Pytest:\n\nEscribe tests para tus funciones en un archivo test_mi_script.py usando Pytest.\n\n(‚òÖ‚òÖ‚òÖ) Aplicaci√≥n de Black y Flake8:\n\nEjecuta Black sobre tu script para estandarizar el estilo (black mi_script.py).\nUtiliza Flake8 para identificar posibles problemas de estilo o errores en tu c√≥digo (flake8 mi_script.py).\n\n(‚òÖ‚òÖ‚òÖ) Medici√≥n de Code Coverage:\n\nUtiliza Coverage para medir la cobertura de tus tests. Ejecuta los tests con Coverage y verifica que cubran la totalidad de tus funciones.\n\n(‚òÖ‚òÖ‚òÖ) An√°lisis de Tipos con Mypy:\n\nEjecuta Mypy para asegurarte de que las anotaciones de tipos en tu script sean correctas (mypy mi_script.py).",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#user-interface",
    "href": "tps/tp_0.html#user-interface",
    "title": "TP0: Tooling",
    "section": "User Interface (‚òÖ‚òÖ‚òÖ)",
    "text": "User Interface (‚òÖ‚òÖ‚òÖ)\nNaturalmente, todos llegamos a un punto en la vida en el cual conectamos cientos de cablecitos para que se hablen (una base de datos con una API, que le habla a otra API a trav√©s de internet, que a su vez es capaz de intentar dominar al mundo) pero si no tenemos algo gr√°fico que nos permita visualizar c√≥mo todo funciona, quiz√°s nos sintamos un poco vac√≠os. O quiz√°s el vac√≠o sea existencial.\nDesde esta perspectiva, es com√∫n buscar crear interfaces de usuario gr√°ficas que nos permitan interactuar con nuestros programas. Hoy les presento Streamlit, que es una librer√≠a de python que nos permite tener una interfaz gr√°fica sencilla funcionando en muy poco tiempo.\n\nEjercicios\n\n(‚òÖ‚òÖ‚òÖ) Prueba de streamlit: Seguir el tutorial Create an app de Streamlit para crear una aplicaci√≥n de prueba.\n(‚òÖ‚òÖ‚òÖ) Database management: Usando SQLAlchemy y pandas, crear una aplicaci√≥n que permita controlar la base de datos del ejercicio 1 de SQL.\n(‚òÖ‚òÖ‚òÖ) API UI Wrapper: Usando SQLAlchemy, pandas, y FastAPI, crear una aplicaci√≥n que permita controlar la base de datos del ejercicio 2 de APIs.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#docker",
    "href": "tps/tp_0.html#docker",
    "title": "TP0: Tooling",
    "section": "Docker (‚òÖ‚òÖ‚òÖ)",
    "text": "Docker (‚òÖ‚òÖ‚òÖ)\n¬øEscucharon alguna vez: ‚Äúen mi computadora funciona, no s√© por qu√© en la tuya no‚Äù? El objetivo de docker es erradicar esa problem√°tica. Docker es un sistema que permite, a trav√©s de im√°genes, enviar sistemas operativos con aplicaciones preinstaladas en ‚Äúcontenedores‚Äù, que funcionan directamente sobre una plataforma de docker, como una versi√≥n ‚Äúlightweight‚Äù de m√°quinas virtuales.\nLa genialidad de esto no es s√≥lo el hecho de hacer un container con una aplicaci√≥n, que ponga-donde-se-ponga funciona, sino tambi√©n la enorme capacidad de componer estos containers. Es decir: podemos hacer una aplicaci√≥n completa con bloquecitos: una API, un modelo, una cache, una base de datos, etc√©tera. B√°sicamente logra que terminemos jugando con legos en vez de escribiendo c√≥digo. Si bien esto se puede hacer de muchas formas, la m√°s sencilla es docker-compose.\n\nEjercicios\n\n(‚òÖ‚òÖ‚òÖ) Imagen de API: A partir del ejercicio 1 de FastAPI, escribir un Dockerfile que, a partir de la imagen base de python-3.9, permita correr el servidor propuesto. Tutorial: https://fastapi.tiangolo.com/deployment/docker/.\n(‚òÖ‚òÖ‚òÖ) Imagen de DB: Resolver el ejercicio 1 de la gu√≠a de SQL utilizando una imagen de docker de PostgreSQL.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_0.html#microservices",
    "href": "tps/tp_0.html#microservices",
    "title": "TP0: Tooling",
    "section": "Microservices (‚òÖ‚òÖ‚òÖ‚òÖ)",
    "text": "Microservices (‚òÖ‚òÖ‚òÖ‚òÖ)\nA partir de lo visto en Docker, APIs y SQL, construyamos una aplicaci√≥n conteinarizada que tenga una interfaz gr√°fica, una API y una base de datos.\n\n\n\nArquitectura b√°sica para la aplicaci√≥n containerizada\n\n\n\nEjercicios\n\n(‚òÖ‚òÖ‚òÖ‚òÖ) Integraci√≥n: Reutilizar el ejercicio 1 y 2 de Docker en un archivo de docker-compose para resolver el ejercicio 2 de APIs, y agregar adem√°s una interfaz gr√°fica a trav√©s del ejercicio 2 de User Interface.",
    "crumbs": [
      "Practicas",
      "TP0: Tooling"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenidos!üëã",
    "section": "",
    "text": "Bienvenidos!üëã\nBienvenidos a la p√°gina de Fundamentos de Machine Learning del Instituto Balseiro. Esta p√°gina act√∫a como repositorio de todos los elementos que pueden llegar a necesitar para el desarrollo de la misma:\n\nClases te√≥ricas.\nTrabajos pr√°cticos.\n\nLorem Ipsum?\nCronograma?\nPrograma?\nMetodolog√≠a de evaluaci√≥n?\nBibliograf√≠a?\nC√°tedra?\nSi la inflamaci√≥n se va, el dolor vuelve?"
  },
  {
    "objectID": "lectures/clase_0.html",
    "href": "lectures/clase_0.html",
    "title": "L0: Tooling",
    "section": "",
    "text": "Completar con lo que demos en la lecture",
    "crumbs": [
      "Lectures",
      "L0: Tooling"
    ]
  },
  {
    "objectID": "tps/tp_1.html",
    "href": "tps/tp_1.html",
    "title": "TP1: Data/Error",
    "section": "",
    "text": "El TP1 apunta a familiarizarse con el manejo de datos y algunas tecnicas de preprocesado, ademas de metricas de bondad y funciones de perdida. Por sobre todo, el ejercicio entregable de este TP es ‚ÄúEDA‚Äù, que tiene maximo sentido debido a que es una herramienta fundamental de takeaway practico de esta tematica.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#resumen",
    "href": "tps/tp_1.html#resumen",
    "title": "TP1: Data/Error",
    "section": "",
    "text": "El TP1 apunta a familiarizarse con el manejo de datos y algunas tecnicas de preprocesado, ademas de metricas de bondad y funciones de perdida. Por sobre todo, el ejercicio entregable de este TP es ‚ÄúEDA‚Äù, que tiene maximo sentido debido a que es una herramienta fundamental de takeaway practico de esta tematica.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#accuracy-and-loss-functions",
    "href": "tps/tp_1.html#accuracy-and-loss-functions",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ) 1. Accuracy and Loss functions",
    "text": "(‚òÖ) 1. Accuracy and Loss functions\nA fin de experimentar con metricas de bondad y funciones de perdida, implemente las funciones que encontrara en el ejercicio 1 del repositorio base, respetando las interfaces propuestas para cada una de ellas:\ndef read_from_csv(filename: str) -&gt; Tuple[pd.Series, pd.Series]: ...\n\ndef precision(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\n\ndef recall(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\n\ndef f1_score(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\n\ndef mse(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\n\ndef cross_entropy(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\ny escriba un main que ejercite estas implementaciones utilizando el archivo ej1.csv.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#confusion-matrix",
    "href": "tps/tp_1.html#confusion-matrix",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ) 2. Confusion Matrix",
    "text": "(‚òÖ) 2. Confusion Matrix\nImplemente la funcion dada por la siguiente firma:\ndef confusion_matrix(y_true: pd.Series, y_pred: pd.Series) -&gt; float: ...\ny utilice los tres archivos provistos en un main para graficar matrices de confusion en variables binarias y de multiples clases. Encuentra algun patron significativo en los datos?",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#numerical-and-categorical-features",
    "href": "tps/tp_1.html#numerical-and-categorical-features",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ) 3. Numerical and Categorical features",
    "text": "(‚òÖ) 3. Numerical and Categorical features\nSe brinda un dataset de juguete en el archivo ej3.csv. Se pide implementar dos funciones:\ndef histogram(feature: pd.Series, n_bins: int) -&gt; pd.Series: ...\n\ndef one_hot_encoder(feature: pd.Series) -&gt; pd.DataFrame: ...\nUtilice estas funciones dentro de un main que las ejercite con el dataset de juguete, para cada una de las features numericas y categoricas.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#over-and-underfitting",
    "href": "tps/tp_1.html#over-and-underfitting",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ) 4. Over and Underfitting",
    "text": "(‚òÖ) 4. Over and Underfitting\nSe provee un csv que contiene tres pares de curvas de entrenamiento, de funcion de perdida de entrenamiento y de validacion. Se pide implementar las siguientes funciones:\ndef read_from_csv(filename: str) -&gt; Tuple[Tuple[pd.Series, pd.Series]]: ...\n\ndef plot_loss(loss_train: pd.Series, loss_val: pd.Series) -&gt; None: ...\ndonde plot_loss permite graficar la funcion de perdida. Ejercite esta implementacion en un main. Ademas, rellene la funcion ‚Äúwrite_results‚Äù de forma que se identifiquen claramente los casos y suba el archivo .csv al repositorio.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#eda-a-entregar",
    "href": "tps/tp_1.html#eda-a-entregar",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ) 5. EDA [A entregar]",
    "text": "(‚òÖ) 5. EDA [A entregar]\nComplete el archivo ej5.ipynb que encontrara dentro del repositorio. Este notebook contiene la estructura b√°sica de un EDA, completa las celdas requeridas y responde con tus propias palabras a las preguntas planteadas. Este archivo sera corregido in-situ por la catedra, es decir, no tiene tests automaticos.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_1.html#calibration-curves",
    "href": "tps/tp_1.html#calibration-curves",
    "title": "TP1: Data/Error",
    "section": "(‚òÖ‚òÖ) 6. Calibration Curves",
    "text": "(‚òÖ‚òÖ) 6. Calibration Curves\nUna herramienta sumamente util a la hora de diagnosticar el comportamiento de un modelo clasico es su curva de calibracion (tambien llamado reliability diagram). En general, partiendo de los valores reales \\(y \\in \\{1, 0\\}\\) y la probabilidad predicha de que \\(y == 1\\), \\(p_y \\in [0, 1]\\), la curva de calibracion obtiene bines. De su explicacion en la documentacion de sklearn:\nCalibration curves, also referred to as reliability diagrams (Wilks 1995 [2]), compare how well the probabilistic predictions of a binary classifier are calibrated. It plots the frequency of the positive label (to be more precise, an estimation of the conditional event probability) on the y-axis against the predicted probability predict_proba of a model on the x-axis. The tricky part is to get values for the y-axis. In scikit-learn, this is accomplished by binning the predictions such that the x-axis represents the average predicted probability in each bin. The y-axis is then the fraction of positives given the predictions of that bin, i.e. the proportion of samples whose class is the positive class (in each bin).\nUtilizando la liberia sklearn, grafique la curva de calibracion para los datos presentados en el archivo ej6.csv.",
    "crumbs": [
      "Practicas",
      "TP1: Data/Error"
    ]
  },
  {
    "objectID": "tps/tp_3.html#resumen",
    "href": "tps/tp_3.html#resumen",
    "title": "TP3: Unsupervised Learning",
    "section": "Resumen",
    "text": "Resumen\nEl TP3 apunta a familiarizarse con algoritmos de aprendizaje no supervisado, tales como clustering, descomposici√≥n en componentes principales y algoritmos de reducci√≥n de la dimensionalidad. Esta gu√≠a tiene tres ejercicios solamente, de los cuales los primeros dos son entregables.\nEncontrar√° los ejercicios con diferentes marcas:\n\n‚òÖ: Ejercicio Obligatorio - no ten√©s opci√≥n.\n‚òÖ‚òÖ: Ejercicio recomendado - hacelo, que no te gane la timidez.\n‚òÖ‚òÖ‚òÖ: Ejercicio avanzado - preguntate dos veces si quer√©s entrar en el rabbit hole.\n‚òÖ‚òÖ‚òÖ‚òÖ: Ejercicio de integraci√≥n - if you gaze long into an abyss, the abyss also gazes into you.\n\n\nLink al repositorio\n\n\nImportante:\nEs probable que no funcionen los tests autom√°ticos del autograding en github, estamos trabajando en solucionarlo. Una vez que lo hayamos solucionado les avisaremos para que hagan un pull a su repositorio local con los cambios que hayamos efectuado; mientras tanto les recomendamos correr los tests de manera local con pytest, para obtener feedback autom√°tico. Mil disculpas, gracias por tanto.",
    "crumbs": [
      "Practicas",
      "TP3: Unsupervised Learning"
    ]
  },
  {
    "objectID": "tps/tp_3.html#clustering-k-means",
    "href": "tps/tp_3.html#clustering-k-means",
    "title": "TP3: Unsupervised Learning",
    "section": "(‚òÖ) 1. Clustering K-means",
    "text": "(‚òÖ) 1. Clustering K-means\n\nImplementa el algoritmo KMeans en el script ej1/k_means.py\nEmplea el notebook ej1/explore_train.ipynb para explorar el archivo ej1/data/synthetic_dataset_1.csv. Posteriormente ‚Äúentrena/fitea‚Äù el algoritmo KMeans que implementaste anteriormente para etiquetar los puntos seg√∫n los K clusters.\nVar√≠a el n√∫mero K para armar ‚Äúthe elbow curve‚Äù y elige el K √≥ptimo (agrega tu respuesta en una celda).\nExplora el archivo data/synthetic_dataset_2.csv y agrupa en clusters usando KMeans.\nUtiliza el algoritmo DBSCAN (Density-Based Spatial Clustering of Applications with Noise) disponible en la librer√≠a sklearn para agrupar en clusters los datos (en el notebook ej1/ej1_explore_train.ipynb).",
    "crumbs": [
      "Practicas",
      "TP3: Unsupervised Learning"
    ]
  },
  {
    "objectID": "tps/tp_3.html#pca",
    "href": "tps/tp_3.html#pca",
    "title": "TP3: Unsupervised Learning",
    "section": "(‚òÖ) 2. PCA",
    "text": "(‚òÖ) 2. PCA\n\nHaz un breve EDA del dataset ‚ÄúWine‚Äù de sklearn en el notebook ej2/ej2_explore_train.ipynb. Grafica la variable targetpara distintas combinaciones de 2 features (una en el eje horizontal y otra en el vertical). A oj√≠metro: ¬øPuedes agrupar los tipos de vino f√°cilmente en alg√∫n subespacio de features?\nTu tarea es completar la implementaci√≥n de la clase PCA en el archivo pca.py.\nUna vez que hayas completado la clase PCA, √∫sala para determinar los componentes principales del conjunto de datos ‚ÄúWine‚Äù de sklearn en el notebook ej2/ej2_explore_train.ipynb.\nMuestra e interpreta tus resultados.\nDetermina de vuelta las componentes principales, pero esta vez usando la librer√≠a sklearn.\nObtener los loadings de las variables en los componentes principales. Hint:use pca.components_, Nos interesa saber los factores m√°s importantes a la hora de elegir un vino!.\n(Opcional) ¬øC√≥mo podr√≠a agregarle esta funcionalidad a su implementaci√≥n?",
    "crumbs": [
      "Practicas",
      "TP3: Unsupervised Learning"
    ]
  },
  {
    "objectID": "tps/tp_3.html#embeddings-y-reducci√≥n-de-la-dimensionalidad",
    "href": "tps/tp_3.html#embeddings-y-reducci√≥n-de-la-dimensionalidad",
    "title": "TP3: Unsupervised Learning",
    "section": "(‚òÖ‚òÖ) 3. Embeddings y Reducci√≥n de la dimensionalidad",
    "text": "(‚òÖ‚òÖ) 3. Embeddings y Reducci√≥n de la dimensionalidad\n\nRecursos disponibles:\n\nModelo de Vocabulario: Se proporciona un archivo de vectores FastText pre-entrenado en formato .vec. Puedes descargar el archivo de vectores desde el siguiente enlace:\n\nDescargar vectores FastText en espa√±ol.\nUna vez que tengas descargado el modelo de vectores, guardalo en la carpeta ‚Äòej3/vec_model‚Äô.\n\nFunci√≥n load_vectors en el notebook ej3/ej3.ipynb: Utiliza esta funci√≥n proporcionada para cargar los embeddings de palabras, y contin√∫a la implementaci√≥n de las tareas asignadas en ese notebook.\n\n\n\nTareas:\n\nReducci√≥n de Dimensionalidad:\n\nAplica un algoritmo de reducci√≥n de dimensionalidad para transformar los embeddings de palabras desde su espacio original a un espacio de 3 componentes. Puedes elegir entre t-SNE, o UMAP para esta tarea.\nGuarda los resultados de la transformaci√≥n para la visualizaci√≥n posterior.\n\nVisualizaci√≥n en 3D:\n\nUtiliza una herramienta de visualizaci√≥n din√°mica como Plotly para crear un gr√°fico tridimensional interactivo de las palabras transformadas.\nCada punto en el gr√°fico debe estar etiquetado con la palabra correspondiente para facilitar la identificaci√≥n.\nIncluye ejes claramente marcados y proporciona una breve descripci√≥n de lo que representa cada eje.\n\nInterpretaci√≥n:\n\nAnaliza el gr√°fico y discute c√≥mo las palabras con significados similares est√°n agrupadas.\nReflexiona sobre si la reducci√≥n de dimensionalidad ha logrado capturar y visualizar relaciones sem√°nticas entre palabras.\nIdentifica cualquier agrupaci√≥n interesante o patrones inesperados y ofrece posibles explicaciones para estos hallazgos.",
    "crumbs": [
      "Practicas",
      "TP3: Unsupervised Learning"
    ]
  }
]